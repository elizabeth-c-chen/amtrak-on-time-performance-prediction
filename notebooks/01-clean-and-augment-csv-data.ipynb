{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83e11642-fdbb-41c1-83ae-75c1412b5f72",
   "metadata": {},
   "source": [
    "## Imports/Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b2a3036-ee51-40cb-b5b0-067b640d5f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fac4407-da01-4631-9f2a-5ef243c66f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "northbound = [[66, 82, 86, 88, 94, 132, 176, 178, 190, 194, 150, 160, 162, 164, 166, 168, 170, 172, 174]]\n",
    "southbound = [[67, 93, 95, 99, 135, 169, 177, 137, 139, 161, 163, 165, 167, 171, 173, 175, 195]]\n",
    "\n",
    "all_trains = sorted(northbound[0] + southbound[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1012fd9-0058-40bf-be86-6ba6528b8998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n"
     ]
    }
   ],
   "source": [
    "years = [year for year in range(2011, 2024+1)]\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63412a03-c217-43e2-8fcd-811440d48185",
   "metadata": {},
   "source": [
    "## Create output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecb3a8e9-7c1d-49eb-acec-22823f2c7fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    for train_num in all_trains:\n",
    "        train_subfolder = f\"../data/3-augmented/{year}/{train_num}\"\n",
    "        try:\n",
    "            os.makedirs(train_subfolder, exist_ok=True)\n",
    "        except :\n",
    "            print(f\"Failed to create folder for train number {train_num}.\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22f4d4dc-0f95-446a-b6e8-f57f55ca928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_custom_time(time_str):\n",
    "    \"\"\"\n",
    "    Parses a time string like '450P' or '125A' and returns a datetime.time object.\n",
    "    \"\"\"\n",
    "    if pd.isna(time_str) or time_str == '*':\n",
    "        return pd.NaT\n",
    "    \n",
    "    time_str = str(time_str)\n",
    "    am_pm = time_str[-1].upper()\n",
    "    time_val = time_str[:-1]\n",
    "\n",
    "    # Handle cases where the time is a single digit hour\n",
    "    if len(time_val) == 3:\n",
    "        hour = int(time_val[0])\n",
    "        minute = int(time_val[1:])\n",
    "    else:\n",
    "        hour = int(time_val[:2])\n",
    "        minute = int(time_val[2:])\n",
    "\n",
    "    # Adjust hour for AM/PM logic\n",
    "    if am_pm == 'P' and hour != 12:\n",
    "        hour += 12\n",
    "    elif am_pm == 'A' and hour == 12:  # Special case for 12 AM\n",
    "        hour = 0\n",
    "    \n",
    "    return pd.to_datetime(f\"{hour:02d}:{minute:02d}\", format='%H:%M').time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28599a44-fb49-4d34-8c82-cab72fd29f8c",
   "metadata": {},
   "source": [
    "## Augment raw data with information from filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df911b6d-f53d-45af-be66-bb0072d07795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n"
     ]
    }
   ],
   "source": [
    "exceptions = []\n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "    for train_num in all_trains:\n",
    "        input_dir = f\"../data/2-csv/{year}/{train_num}\"\n",
    "        output_dir = f\"../data/3-augmented/{year}/{train_num}\"\n",
    "        if os.path.exists(input_dir):\n",
    "            num_files = len(os.listdir(input_dir))\n",
    "            #print(f\"    Num files for {year} and {train_num}: {num_files}\")\n",
    "            for file in os.listdir(input_dir):\n",
    "                if not file.startswith(\".\") and not file == 'index.csv':\n",
    "                    try:\n",
    "                        filepath = os.path.join(input_dir, file)\n",
    "                        filename = filepath.split(\"/\")[-1]\n",
    "                        train_number_extracted = filename.split(\"_\")[0]\n",
    "                        date_string = filename.split(\"_\")[1].rstrip(\".csv\")\n",
    "                        date_parsed = datetime.strptime(date_string, \"%Y%m%d\").date()\n",
    "                        #print(f\"Train Num: {train_number_extracted} | Date Part: {date_parsed}\")\n",
    "                \n",
    "                        df = pd.read_csv(filepath)\n",
    "                        \n",
    "                        # Augment with columns containing actual date of departure and arrival \n",
    "                        origination_date = pd.to_datetime(date_parsed)\n",
    "\n",
    "                        df['Origin Date'] = origination_date\n",
    "                        df['Train Number'] = train_num\n",
    "                        df['Service Disruption'] = 0\n",
    "                        df['Cancellation'] = 0\n",
    "                        \n",
    "                        departure_day_offset = pd.to_numeric(df['Schedule Departure Day'], errors='coerce') - 1\n",
    "                        arrival_day_offset = pd.to_numeric(df['Schedule Arrival Day'], errors='coerce') - 1\n",
    "\n",
    "                        df['Scheduled Departure Date'] = origination_date + pd.to_timedelta(departure_day_offset, unit='d')\n",
    "                        df['Scheduled Arrival Date'] = origination_date + pd.to_timedelta(arrival_day_offset, unit='d')\n",
    "    \n",
    "                        # Augment with columns for actual datetime \n",
    "                        df['Parsed Schedule Departure Time'] = df['Schedule Departure Time'].apply(parse_custom_time)\n",
    "                        df['Parsed Schedule Arrival Time'] = df['Schedule Arrival Time'].apply(parse_custom_time)\n",
    "                        df['Parsed Actual Departure Time'] = df['Actual Departure Time'].apply(parse_custom_time)\n",
    "                        df['Parsed Actual Arrival Time'] = df['Actual Arrival Time'].apply(parse_custom_time)\n",
    "                        \n",
    "                        df['Scheduled Departure Datetime'] = df.apply(\n",
    "                            lambda row: pd.to_datetime(str(row['Scheduled Departure Date']).split()[0] + ' ' + str(row['Parsed Schedule Departure Time'])) \n",
    "                            if pd.notna(row['Scheduled Departure Date']) and pd.notna(row['Parsed Schedule Departure Time'])\n",
    "                            else pd.NaT, axis=1)\n",
    "                        \n",
    "                        df['Scheduled Arrival Datetime'] = df.apply(\n",
    "                            lambda row: pd.to_datetime(str(row['Scheduled Arrival Date']).split()[0] + ' ' + str(row['Parsed Schedule Arrival Time'])) \n",
    "                            if pd.notna(row['Scheduled Arrival Date']) and pd.notna(row['Parsed Schedule Arrival Time'])\n",
    "                            else pd.NaT, axis=1)\n",
    "                        \n",
    "                        df['Actual Departure Datetime'] = df.apply(\n",
    "                            lambda row: pd.to_datetime(str(row['Scheduled Departure Date']).split()[0] + ' ' + str(row['Parsed Actual Departure Time'])) \n",
    "                            if pd.notna(row['Scheduled Departure Date']) and pd.notna(row['Parsed Actual Departure Time'])\n",
    "                            else pd.NaT, axis=1)\n",
    "                        \n",
    "                        df['Actual Arrival Datetime'] = df.apply(\n",
    "                            lambda row: pd.to_datetime(str(row['Scheduled Arrival Date']).split()[0] + ' ' + str(row['Parsed Actual Arrival Time'])) \n",
    "                            if pd.notna(row['Scheduled Arrival Date']) and pd.notna(row['Parsed Actual Arrival Time'])\n",
    "                            else pd.NaT, axis=1)\n",
    "    \n",
    "                        # Output cleaned + augmented data\n",
    "                        df = df[['Origin Date', 'Train Number', 'Service Disruption', 'Cancellation', 'Station Code','Scheduled Departure Datetime', 'Scheduled Arrival Datetime', 'Actual Departure Datetime', 'Actual Arrival Datetime', 'Comments']]\n",
    "                        output_filepath = os.path.join(output_dir, file)                   \n",
    "                        df.to_csv(output_filepath, index=False)\n",
    "                    except ValueError as e:\n",
    "                        exceptions.append([filepath, e])\n",
    "                    except IndexError as e:\n",
    "                        exceptions.append([filepath, e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "007c7a2a-4e54-4758-b9c9-f0d037ce15d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2286"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exceptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "111f99e0-8ebd-4f76-9baa-173c2dc17424",
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions = pd.DataFrame(exceptions, columns=['filepath', 'error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d27d6555-05b3-4f07-b17a-7e6354710e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptions.to_csv(\"exceptions_full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65bbba6-d5c3-46a5-9976-31ef3579f98d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
